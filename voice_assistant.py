# -*- coding: utf-8 -*-
"""Voice_assistant.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13q-QKWNQZ4tNijaKO_I1l2lgFt30rP5i

# **Prepoznavac govora**
"""

import numpy as np
import scipy.io.wavfile as wf
from tkinter import *
from tkinter.ttk import *
from tkinter import messagebox
import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
!pip install -q omegaconf torchaudio pydub

import os
from os.path import exists

if not exists('silero-models'):
  !git clone -q --depth 1 https://github.com/snakers4/silero-models

# %cd silero-models

# silero imports
import torch
import random
from glob import glob
from omegaconf import OmegaConf

from colab_utils import record_audio
                         

# imports for uploading/recording
import numpy as np
import ipywidgets as widgets
from scipy.io import wavfile
from IPython.display import Audio, display, clear_output
from torchaudio.functional import vad

import scipy.io.wavfile as wf

def _record_audio(b):
  clear_output()
  audio = record_audio(record_seconds)
  wavfile.write('recorded.wav', sample_rate, (32767*audio).numpy().astype(np.int16))
  display(Audio(audio, rate=sample_rate, autoplay=True))
  wavfile.write('test.wav', sample_rate, (32767*audio).numpy().astype(np.int16))
  openFile('/content/silero-models/recorded.wav')


def openFile(path):

    try:
        samplerate,data = wf.read(path)
        cutFile(samplerate,data)

    except:
        print(f'File {path} not found')


    

def cutFile(samplerate,data):



    #print(self.samplerate)

    T = [i /samplerate for i in range(0, len(data))] #vreme izmedju svakog pojedinacnog sempla
    

    #print(self.T)

    noiseArea = int(samplerate * 0.1)
    noise = np.abs(data[:noiseArea])
    L = np.mean(noise) + 2 * np.std(noise)


    # L - average noise
    # N - number of samples in window
    N = int(samplerate * 0.01)
   

    length = len(data)

    words = [1 if np.mean(np.abs(data[i:i+N])) > L else 0 for i in range(0, length, N)]


    
  
    


    flattenup(words, 12)

    flattendown(words, 20)

    
    global shum


    try:
        words.index(1)
        shum = False

    except:
        print('SUM')
        shum = True
        #self.drawNoise()


    # self.window_function()




def flattenup(words, p):
    curr_len = 0
    index = 0
    for i in words:
        if i == 0:
            curr_len += 1
        else:
            if p > curr_len > 0:
                for j in range(index - curr_len, index):
                    words[j] = 1
            curr_len = 0
        index += 1
    

    
def flattendown(words, q):
    curr_len = 0
    index = 0
    for i in words:
        if i == 1:
            curr_len += 1
        else:
            if q > curr_len > 0:
                for j in range(index - curr_len, index):
                    words[j] = 0
            curr_len = 0
        index += 1
    



record_seconds = 5
sample_rate = 16000

button = widgets.Button(description="Record Speech")
button.on_click(_record_audio)
display(button)

SPEECH_FILE='/content/silero-models/recorded.wav'

"""# **Speech-to-Text**"""

import IPython
import requests
import torch
import torchaudio
import matplotlib

!git clone https://github.com/IgnjatKrdzavac/AudioFilesDeepLearning.git

!pip install datasets==1.4.1
!pip install soundfile
!pip install jiwer
!pip install transformers[torch]

!pip install librosa

import pandas as pd

#ourdata = pd.read_csv("/content/AudioFilesDeepLearning/Audio Files.csv")
ourdata = pd.read_csv("/content/silero-models/AudioFilesDeepLearning/Audio Files.csv")
ourdata['file'] = ourdata['file'].map(lambda x: "/content/silero-models/AudioFilesDeepLearning"+x)
ourdata

from datasets import Dataset

ourdataset =  Dataset.from_pandas(ourdata)
print(ourdataset)

from datasets import ClassLabel
import random
import pandas as pd
from IPython.display import display, HTML

def show_random_elements(dataset, num_examples=5):
    assert num_examples <= len(dataset), "Can't pick more elements than there are in the dataset."
    picks = []
    for _ in range(num_examples):
        pick = random.randint(0, len(dataset)-1)
        while pick in picks:
            pick = random.randint(0, len(dataset)-1)
        picks.append(pick)
    
    df = pd.DataFrame(dataset[picks])
    display(HTML(df.to_html()))

show_random_elements(ourdataset.remove_columns(["file"]), num_examples=5)

import re
chars_to_ignore_regex = '[\,\?\.\!\-\;\:\"]'

def remove_special_characters(batch):
    batch["text"] = re.sub(chars_to_ignore_regex, '', batch["text"]).lower() + " "
    return batch

ourdataset = ourdataset.map(remove_special_characters)

show_random_elements(ourdataset.remove_columns(["file"]), num_examples=5)

def extract_all_chars(batch):
  all_text = " ".join(batch["text"])
  vocab = list(set(all_text))
  return {"vocab": [vocab], "all_text": [all_text]}

vocabs = ourdataset.map(extract_all_chars, batched=True, batch_size=1, keep_in_memory=True)
vocabs

vocab_listBgd = list(set("kakvo je vreme u beogradu"))
vocab_listLdn = list(set("kakvo je vreme u novom sadu"))
vocab_listNsd = list(set("kakvo je vreme u londonu"))



vocab_listsadness2= list(set("osecam se jadno i nju nije briga"))


vocab_joy = list(set("treniram svako jutro i osecam se sjajno povodom toga"))


vocab_listfear2  = list(set("osecam se stidljivo zbog onoga sto nosim"))




in_first = set(vocab_listBgd)
in_second = set(vocab_listLdn)
in_third = set(vocab_listNsd)

in_second_but_not_in_first = in_second - in_first

resultBgd_Ldn = vocab_listBgd + list(in_second_but_not_in_first)

in_firstAndSecond = set(resultBgd_Ldn)

in_third_but_not_in_firstAndSecond = in_third - in_firstAndSecond

resultBLNS = resultBgd_Ldn + list(in_third_but_not_in_firstAndSecond)






in_fear2 = set(vocab_listfear2)


in_joy = set(vocab_joy)

in_sadness = set(vocab_listsadness2)









 

resultBLNS.append('i')
resultBLNS.append('c')
resultBLNS.append('j')
resultBLNS.append('z')
resultBLNS.append('t')


print(resultBLNS)
print(in_joy)

resultBLNS.append('p')

print(resultBLNS)

vocab_dict = {v: k for k, v in enumerate(resultBLNS)}
vocab_dict

vocab_dict["|"] = vocab_dict[" "]
del vocab_dict[" "]

vocab_dict["[UNK]"] = len(vocab_dict)
vocab_dict["[PAD]"] = len(vocab_dict)
len(vocab_dict)

# import json
# with open('vocab.json', 'w') as vocab_file:
#     json.dump(vocab_dict, vocab_file)

from transformers import Wav2Vec2CTCTokenizer

tokenizer = Wav2Vec2CTCTokenizer("/content/drive/MyDrive/wav2vec2-base-mine/vocab.json", unk_token="[UNK]", pad_token="[PAD]", word_delimiter_token="|")
#tokenizer = Wav2Vec2CTCTokenizer("./vocab.json", unk_token="[UNK]", pad_token="[PAD]", word_delimiter_token="|")

# tokenizer.save_pretrained("/content/drive/MyDrive/wav2vec2-base-mine/")

"""## **Feature extraction**"""

from transformers import Wav2Vec2FeatureExtractor

feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)
#feature_extractor.save_pretrained("/content/drive/MyDrive/testmodel/")
#feature_extractor.save_pretrained("/content/drive/MyDrive/wav2vec2-base-mine/")

from transformers import Wav2Vec2Processor

processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)

#processor.save_pretrained("/content/drive/MyDrive/wav2vec2-base-mine/")

ourdataset[0]

import librosa

def speech_file_to_array_fn(batch):
    speech_array, sampling_rate = librosa.load(batch["file"], sr=16000)
    batch["speech"] = speech_array
    batch["sampling_rate"] = sampling_rate
    batch["target_text"] = batch["text"]
    return batch

ourdataset = ourdataset.map(speech_file_to_array_fn, num_proc=4)

import IPython.display as ipd
import numpy as np
import random

rand_int = random.randint(0, len(ourdataset)-1)
print(ourdataset[rand_int])
ipd.Audio(data=np.asarray(ourdataset[rand_int]["speech"]), rate=ourdataset[rand_int]["sampling_rate"])

from google.colab import drive
drive.mount('/content/drive')

rand_int = random.randint(0, len(ourdataset)-1)

print("Target text:", ourdataset[rand_int]["target_text"])
print("Input array shape:", np.asarray(ourdataset[rand_int]["speech"]).shape)
print("Sampling rate:", ourdataset[rand_int]["sampling_rate"])

# def prepare_dataset(batch):
#     # check that all files have the correct sampling rate
#     assert (
#         len(set(batch["sampling_rate"])) == 1
#     ), f"Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}."

#     batch["input_values"] = processor(batch["speech"], sampling_rate=batch["sampling_rate"][0]).input_values
    
#     with processor.as_target_processor():
#         batch["labels"] = processor(batch["target_text"]).input_ids
#     return batch

# ourdataset_prepared = ourdataset.map(prepare_dataset, batch_size=1, num_proc=4, batched=True)

import torch

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Union

@dataclass
class DataCollatorCTCWithPadding:
    """
    Data collator that will dynamically pad the inputs received.
    Args:
        processor (:class:`~transformers.Wav2Vec2Processor`)
            The processor used for proccessing the data.
        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):
            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)
            among:
            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single
              sequence if provided).
            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the
              maximum acceptable input length for the model if that argument is not provided.
            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of
              different lengths).
        max_length (:obj:`int`, `optional`):
            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).
        max_length_labels (:obj:`int`, `optional`):
            Maximum length of the ``labels`` returned list and optionally padding length (see above).
        pad_to_multiple_of (:obj:`int`, `optional`):
            If set will pad the sequence to a multiple of the provided value.
            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=
            7.5 (Volta).
    """

    processor: Wav2Vec2Processor
    padding: Union[bool, str] = True
    max_length: Optional[int] = None
    max_length_labels: Optional[int] = None
    pad_to_multiple_of: Optional[int] = None
    pad_to_multiple_of_labels: Optional[int] = None

    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:
        # split inputs and labels since they have to be of different lenghts and need
        # different padding methods
        input_features = [{"input_values": feature["input_values"]} for feature in features]
        label_features = [{"input_ids": feature["labels"]} for feature in features]

        batch = self.processor.pad(
            input_features,
            padding=self.padding,
            max_length=self.max_length,
            pad_to_multiple_of=self.pad_to_multiple_of,
            return_tensors="pt",
        )
        with self.processor.as_target_processor():
            labels_batch = self.processor.pad(
                label_features,
                padding=self.padding,
                max_length=self.max_length_labels,
                pad_to_multiple_of=self.pad_to_multiple_of_labels,
                return_tensors="pt",
            )

        # replace padding with -100 to ignore loss correctly
        labels = labels_batch["input_ids"].masked_fill(labels_batch.attention_mask.ne(1), -100)

        batch["labels"] = labels

        return batch

# data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)

from datasets import load_metric
wer_metric = load_metric("wer")

def compute_metrics(pred):
    pred_logits = pred.predictions
    pred_ids = np.argmax(pred_logits, axis=-1)

    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id

    pred_str = processor.batch_decode(pred_ids)
    # we do not want to group tokens when computing the metrics
    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)

    wer = wer_metric.compute(predictions=pred_str, references=label_str)

    return {"wer": wer}

from transformers import Wav2Vec2ForCTC

# model = Wav2Vec2ForCTC.from_pretrained(
#     "facebook/wav2vec2-base", 
#     gradient_checkpointing=True, 
#     ctc_loss_reduction="mean", 
#     pad_token_id=processor.tokenizer.pad_token_id,
# )

# model.freeze_feature_extractor()

# from transformers import TrainingArguments

# training_args = TrainingArguments(
#   # output_dir="/content/drive/MyDrive/wav2vec2-base-timit-demo",
#   # output_dir="/content/drive/MyDrive/wav2vec2-base-mine/",
#   #output_dir="/content/drive/MyDrive/testmodel/",
#   group_by_length=True,
#   per_device_train_batch_size=1,
#   evaluation_strategy="steps",
#   num_train_epochs=500,
#   fp16=True,
#   save_steps=500,
#   eval_steps=500,
#   logging_steps=100,
#   learning_rate=1e-4,
#   weight_decay=0.005,
#   warmup_steps=100,
#   save_total_limit=20,
# )

# from transformers import Trainer

# trainer = Trainer(
#     model=model,
#     data_collator=data_collator,
#     args=training_args,
#     compute_metrics=compute_metrics,
#     train_dataset=ourdataset_prepared,
#     eval_dataset=ourdataset_prepared,
#     tokenizer=processor.feature_extractor,
# )

# trainer.train()

def map_to_result(batch):
  model.to("cuda")
  input_values = processor(
      batch["speech"], 
      sampling_rate=batch["sampling_rate"], 
      return_tensors="pt"
  ).input_values.to("cuda")

  with torch.no_grad():
    logits = model(input_values).logits

  pred_ids = torch.argmax(logits, dim=-1)
  batch["pred_str"] = processor.batch_decode(pred_ids)[0]
  
  return batch

# results = ourdataset.map(map_to_result)

# print("Test WER: {:.3f}".format(wer_metric.compute(predictions=results["pred_str"], references=results["target_text"])))

# show_random_elements(results.remove_columns(["speech", "sampling_rate"]))

model = Wav2Vec2ForCTC.from_pretrained("/content/drive/MyDrive/wav2vec2-base-mine/checkpoint-20000")

results1 = ourdataset.map(map_to_result)

print("Test WER: {:.3f}".format(wer_metric.compute(predictions=results1["pred_str"], references=results1["target_text"])))

show_random_elements(results1.remove_columns(["speech", "sampling_rate"]))

"""# **Spoljasnji API**

"""

import requests
import sys

def spoljasnjiApi(flagLondon,flagNoviSad,flagBeograd):
  flagNista = 0

  # NOVI SAD: lat:45.267136, lon:19.833549
  # BELGRADE: lat:44.8178131, lon:20.4568974
  # LONDON: lat:51.5073219, lon:-0.1276474

  # insert your real key here!
  access_key = "52c092f9-69d6-405d-8d12-00e3c95d8c76"

  headers = {
      "X-Meteum-API-Key": access_key
  }
  if(flagLondon == 1):
    query = """{
      weatherByPoint(request: { lat: 51.5073219, lon: -0.1276474}) {
        now {
          temperature
        }
      }
    }"""
  elif(flagBeograd == 1):
    query = """{
      weatherByPoint(request: { lat: 44.786568, lon: 20.448921}) {
        now {
          temperature
        }
      }
    }"""

  elif(flagNoviSad == 1):
    query = """{
      weatherByPoint(request: { lat: 45.267136, lon: 19.833549}) {
        now {
          temperature
        }
      }
    }"""
  else:  
      flagNista = 1
      resultVreme = "Nepoznata komanda, pokušajte ponovo"
      
  if(flagNista == 0):
    response = requests.post('https://api.meteum.ai/graphql/query', headers=headers, json={'query': query})


    splitted = response.text.split(":")
    splittedNmbr = splitted[4]
    if(splittedNmbr[1].isnumeric()):
      temperatura = splittedNmbr[0] +  splittedNmbr[1]
    else:
      temperatura = splittedNmbr[0]



  if(flagBeograd == 1):
      resultVreme = f"U Beogradu je trenutno {temperatura} stepeni"
  elif(flagNoviSad == 1):
    resultVreme = f"U Novom Sadu je trenutno {temperatura} stepeni"
  elif(flagLondon == 1):
    resultVreme = f"U Londonu je trenutno {temperatura} stepeni"

  return resultVreme

import requests
def spoljasnjiApi2(flagLondon,flagNoviSad,flagBeograd):  
  flagNista = 0

  url = "https://visual-crossing-weather.p.rapidapi.com/forecast"

  if(flagNoviSad == 1):
    querystring = {"aggregateHours":"24","location":"Novi Sad","contentType":"csv","unitGroup":"us","shortColumnNames":"0"}

    headers = {
      "X-RapidAPI-Key": "453ce24fbcmsh6626bffe125a1d6p15cceejsn91fd99c27fb6",
      "X-RapidAPI-Host": "visual-crossing-weather.p.rapidapi.com"
    }
  elif(flagBeograd == 1):
    querystring = {"aggregateHours":"24","location":"Belgrade","contentType":"csv","unitGroup":"us","shortColumnNames":"0"}

    headers = {
      "X-RapidAPI-Key": "453ce24fbcmsh6626bffe125a1d6p15cceejsn91fd99c27fb6",
      "X-RapidAPI-Host": "visual-crossing-weather.p.rapidapi.com"
    }

  elif(flagLondon == 1):
    querystring = {"aggregateHours":"24","location":"London","contentType":"csv","unitGroup":"us","shortColumnNames":"0"}

    headers = {
      "X-RapidAPI-Key": "453ce24fbcmsh6626bffe125a1d6p15cceejsn91fd99c27fb6",
      "X-RapidAPI-Host": "visual-crossing-weather.p.rapidapi.com"
    }

  else:
     resultVreme = "Nepoznata komanda, pokušajte ponovo" 
     flagNista = 1
  
  if(flagNista == 0):
    response1 = requests.request("GET", url, headers=headers, params=querystring)
    response = response1.text.split(',')
    tempCels = float(response[32])/5.722222
  
  if(flagBeograd == 1):
      resultVreme = f"U Beogradu je trenutno {round(tempCels)} stepeni"
  elif(flagNoviSad == 1):
    resultVreme = f"U Novom Sadu je trenutno {round(tempCels)} stepeni"
  elif(flagLondon == 1):
    resultVreme = f"U Londonu je trenutno {round(tempCels)} stepeni"

  return resultVreme

spoljasnjiApi2(1,0,0)

"""# **NLP Model**

## **Data processing**
"""

import os
for dirname, _, filenames in os.walk('/content/drive/MyDrive/emotions_dataset'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd


from wordcloud import WordCloud
import torch
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
from sklearn.preprocessing import LabelEncoder

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional,Dropout

import re 
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup

test_data = pd.read_csv("/content/drive/MyDrive/emotions_dataset/test.txt", header=None, sep=";", names=["Comment","Emotion"], encoding="utf-8")
train_data = pd.read_csv("/content/drive/MyDrive/emotions_dataset/train.txt", header=None, sep=";", names=["Comment","Emotion"], encoding="utf-8")
validation_data = pd.read_csv("/content/drive/MyDrive/emotions_dataset/val.txt", header=None, sep=";", names=["Comment","Emotion"], encoding="utf-8")
print("Train : ", train_data.shape)
print("Test : ", test_data.shape)
print("Validation : ", validation_data.shape)

train_data.head()

train_data['length'] = [len(x) for x in train_data['Comment']]
train_data.head()

all_data = {'Train Data': train_data, 'Validation Data': validation_data, 'Test Data': test_data}
fig, ax = plt.subplots(1,3, figsize=(30,10))
for i, df in enumerate(all_data.values()):
    df2 = df.copy()
    df2['length'] = [len(x) for x in df2['Comment']]
    sns.kdeplot(data=df2,x='length',hue='Emotion', ax=ax[i])
plt.show()

def words_cloud(wordcloud, df):
    plt.figure(figsize=(10, 10))
    plt.title(df+' Word Cloud', size = 16)
    plt.imshow(wordcloud) 
    # No axis details
    plt.axis("off");

emotions_list = train_data['Emotion'].unique()
emotions_list

for emotion in emotions_list:
    text = ' '.join([sentence for sentence in train_data.loc[train_data['Emotion'] == emotion,'Comment']])
    wordcloud = WordCloud(width = 600, height = 600).generate(text)
    words_cloud(wordcloud, emotion)

"""## **Preprocessing**"""

lb = LabelEncoder()
train_data['Emotion'] = lb.fit_transform(train_data['Emotion'])
test_data['Emotion'] = lb.fit_transform(test_data['Emotion'])
validation_data['Emotion'] = lb.fit_transform(validation_data['Emotion'])

train_data.head()

nltk.download('stopwords')
stopwords = set(nltk.corpus.stopwords.words('english'))

max_len=train_data['length'].max()
max_len

vocabSize = 11000

from tensorflow.keras.preprocessing.text import one_hot
def text_cleaning(df, column):
    """Removing unrelevent chars, Stemming and padding"""
    stemmer = PorterStemmer()
    corpus = []
    
    for text in df[column]:
        text = re.sub("[^a-zA-Z]", " ", text)
        text = text.lower()
        text = text.split()
        text = [stemmer.stem(word) for word in text if word not in stopwords]
        text = " ".join(text)
        corpus.append(text)
    one_hot_word = [one_hot(input_text=word, n=vocabSize) for word in corpus]
    pad = pad_sequences(sequences=one_hot_word,maxlen=max_len,padding='pre')
    print(pad.shape)
    return pad

x_train = text_cleaning(train_data, "Comment")
x_test = text_cleaning(test_data, "Comment")
x_val = text_cleaning(validation_data, "Comment")

y_train = train_data["Emotion"]
y_test = test_data["Emotion"]
y_val = validation_data["Emotion"]

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
y_val = to_categorical(y_val)

"""## **Model building**"""

modelNlp = Sequential()
modelNlp.add(Embedding(input_dim=vocabSize,output_dim=150,input_length=300))
modelNlp.add(Dropout(0.2)) #random neurone iskljucujemo iz treninga
modelNlp.add(LSTM(128)) #RNN
modelNlp.add(Dropout(0.2))
modelNlp.add(Dense(64,activation='sigmoid'))
modelNlp.add(Dropout(0.2))
modelNlp.add(Dense(6,activation='softmax'))

modelNlp.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])
modelNlp.summary()

callback = EarlyStopping(monitor="val_loss", patience=2, restore_best_weights=True)

hist = modelNlp.fit(x_train,y_train,epochs=10,batch_size=64,
                 validation_data=(x_val,y_val), verbose=1, callbacks=[callback])

modelNlp.evaluate(x_val,y_val,verbose=1)

modelNlp.evaluate(x_test,y_test,verbose=1)

modelNlp.save('/content/drive/MyDrive/NLP-Model')

from tensorflow import keras
modelNlp = keras.models.load_model('/content/drive/MyDrive/NLP-Model')

accuracy = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
loss=hist.history['loss']
val_loss=hist.history['val_loss']
epochs=range(len(accuracy))

plt.plot(epochs,accuracy,'b', label='Training accuracy')
plt.plot(epochs,val_acc,'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()

plt.plot(epochs,loss,'b', label='Training loss')
plt.plot(epochs,val_loss,'r', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()

plt.show()

def sentence_cleaning(sentence):
    """Pre-processing sentence for prediction"""
    stemmer = PorterStemmer()
    corpus = []
    text = re.sub("[^a-zA-Z]", " ", sentence)
    text = text.lower()
    text = text.split()
    text = [stemmer.stem(word) for word in text if word not in stopwords]
    text = " ".join(text)
    corpus.append(text)
    one_hot_word = [one_hot(input_text=word, n=vocabSize) for word in corpus]
    pad = pad_sequences(sequences=one_hot_word,maxlen=max_len,padding='pre')
    return pad

# sentences = [
#             "I workout every morning before and feel fabulous for it",
#             "I feel miserable and she doesnt care",
#             "I feel shy because of what i am wearing"
#             ]
# for sentence in sentences:

def nlpSentence():
  konacnaRecenica = "Nepoznata komanda, pokušajte ponovo"

  if(flagRecenicaZaNLP is True):
    
    rezultatSaUlazaC = sentence_cleaning(rezultatSaUlaza)
    result = lb.inverse_transform(np.argmax(modelNlp.predict(rezultatSaUlazaC), axis=-1))[0]
    proba =  np.max(modelNlp.predict(rezultatSaUlazaC))
    print(f"{result} : {proba}\n\n")
    
    if(result == 'joy'):
      konacnaRecenica = "U vašoj rečenici je detektovana SREĆA"
    elif(result == 'fear'):
      konacnaRecenica = "U vašoj rečenici je detektovan STRAH"
    elif(result == 'sadness'):
      konacnaRecenica = "U vašoj rečenici je detektovana TUGA"


  return konacnaRecenica

"""# **Text-to-Speech**"""

pip install gTTS

from IPython.display import Audio, display, clear_output
# Import the required module for text 
# to speech conversion
from gtts import gTTS
  
# This module is imported so that we can 
# play the converted audio
import os

def T2S(text):  
  # The text that you want to convert to audio
  mytext = text
    
  # Language in which you want to convert
  language = 'sr'
    
  # Passing the text and language to the engine, 
  # here we have marked slow=False. Which tells 
  # the module that the converted audio should 
  # have a high speed
  myobj = gTTS(text=mytext, lang=language, slow=False)
    
  # Saving the converted audio in a mp3 file named
  # welcome 
  myobj.save("/content/drive/MyDrive/VR_exitSpeech/izlaz.mp3")
  return "/content/drive/MyDrive/VR_exitSpeech/izlaz.mp3"

  
# Playing the converted file
#os.system("mpg321 welcome.mp3")

"""# **Entry testing**"""

if(shum == False): 
  model.to("cuda")
  speech_array, sampling_rate = librosa.load(SPEECH_FILE, sr=16000)

  input_values = processor(
        speech_array, 
        sampling_rate=sampling_rate, 
        return_tensors="pt"
    ).input_values.to("cuda")


  logits = model(input_values).logits
  pred_ids = torch.argmax(logits, dim=-1)
  resultUlaza = processor.batch_decode(pred_ids)
  print(resultUlaza)





if(shum == True):
  flagLondon = 0
  flagNoviSad = 0
  flagBeograd = 0
elif("kakvo je vreme u novom sadu" in resultUlaza):     
  flagNoviSad = 1
  flagBeograd = 0
  flagLondon = 0
elif("kakvo je vreme u beogradu" in resultUlaza):
  flagBeograd = 1
  flagLondon = 0
  flagNoviSad = 0
elif("kakvo je vreme u londonu" in resultUlaza or 'kakvo j je vreme u londonu' in resultUlaza):
  flagLondon = 1
  flagNoviSad = 0
  flagBeograd = 0

else:
  flagLondon = 0
  flagNoviSad = 0
  flagBeograd = 0


rezultat = spoljasnjiApi2(flagLondon,flagNoviSad,flagBeograd)


flagRecenicaZaNLP = False

if(shum == True):
  flagRecenicaZaNLP = False
elif(("osecam se stidljivo zbog onoga sto nosim" in resultUlaza)or("osecam se stidljivo zbog onoga sto nosi" in resultUlaza)):
  resultUlaza = "I feel shy because of what i am wearing"
  flagRecenicaZaNLP = True
elif(("treniram svako jutro  i osecam se sjajno povodom toga" in resultUlaza) or ("treniram svako jutro i osecam se sjajno povodom toga" in resultUlaza) or ("treniram svako jutro  i osecam se sjajno povodomtoga" in resultUlaza)):
  resultUlaza = "I workout every morning before and feel fabulous for it"
  flagRecenicaZaNLP = True
  
elif("osecam se jadno i nju nije briga" in resultUlaza):
  resultUlaza = "I feel miserable and she doesnt care"
  flagRecenicaZaNLP = True

if(flagRecenicaZaNLP == True):
  print(resultUlaza)  
  rezultatSaUlaza = resultUlaza
  rezultat = nlpSentence()

putanjaDoOdgovora = T2S(rezultat)

display(Audio(putanjaDoOdgovora, rate=16000, autoplay=True))